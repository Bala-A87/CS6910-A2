{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
    "dataset = ImageFolder('../data/train/', transform=transforms)\n",
    "train_dataloader = DataLoader(dataset, 128, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from typing import List, Tuple\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a simple convolutional neural network, with 5 convolutional layers, each followed by maxpooling and optionally batchnorm, and two fully-connected layers.\n",
    "\n",
    "    Args:\n",
    "        filters (List[Tuple[int, int]]): Details of all the convolutional layers, each given by a tuple (num_filters, kernel_size), where num_filters is the number of convolutional filters and kernel_size is the size of the filter.\n",
    "        width_dense (int): The number of units in the hidden fully-connected/dense layer.\n",
    "        input_size (Tuple[int, int], optional): The size of the input images (images are assumed RGB, i.e., 3 channels).\n",
    "            Defaults to (224, 224).\n",
    "        activation_conv (torch.nn.Module, optional): The activation/non-linearity to use for the convolutional layers.\n",
    "            Defaults to torch.nn.ReLU.\n",
    "        activation_conv (torch.nn.Module, optional): The activation/non-linearity to use for the hidden dense layer.\n",
    "            Defaults to torch.nn.ReLU.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        filters: List[Tuple[int, int]],\n",
    "        width_dense: int,\n",
    "        input_size: Tuple[int, int] = (224, 224),\n",
    "        activation_conv: nn.Module = nn.ReLU,\n",
    "        activation_dense: nn.Module = nn.ReLU,\n",
    "        batch_norm: bool = True,\n",
    "        dropout: float = None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=filters[0][0], kernel_size=filters[0][1], padding='same'),\n",
    "            activation_conv(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=filters[0][0]) if batch_norm else nn.Identity(),\n",
    "            nn.Conv2d(in_channels=filters[0][0], out_channels=filters[1][0], kernel_size=filters[1][1], padding='same'),\n",
    "            activation_conv(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=filters[1][0]) if batch_norm else nn.Identity(),\n",
    "            nn.Conv2d(in_channels=filters[1][0], out_channels=filters[2][0], kernel_size=filters[2][1], padding='same'),\n",
    "            activation_conv(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=filters[2][0]) if batch_norm else nn.Identity(),\n",
    "            nn.Conv2d(in_channels=filters[2][0], out_channels=filters[3][0], kernel_size=filters[3][1], padding='same'),\n",
    "            activation_conv(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=filters[3][0]) if batch_norm else nn.Identity(),\n",
    "            nn.Conv2d(in_channels=filters[3][0], out_channels=filters[4][0], kernel_size=filters[4][1], padding='same'),\n",
    "            activation_conv(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=filters[4][0]) if batch_norm else nn.Identity(),\n",
    "        )\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Identity() if dropout is None else nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=int(filters[4][0]*(input_size[0] * input_size[1])/32**2), out_features=width_dense),\n",
    "            activation_dense(),\n",
    "            nn.Identity() if dropout is None else nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features=width_dense, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvNet\n",
    "from metrics import CategoricalAccuracy\n",
    "\n",
    "model = ConvNet(filters=[(16, 3), (32, 3), (64, 3), (128, 3), (64, 3)], width_dense=64, dropout=0.2).to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "metric = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, lengths=[0.8, 0.2])\n",
    "train_dataloader, val_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True), DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import train\n",
    "\n",
    "train(model, train_dataloader, val_dataloader, loss_fn, optimizer, metric, 10, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import ConvNet\n",
    "\n",
    "model = ConvNet(filters=[(128, 3)]*5, width_dense=128, activation_conv=torch.nn.SiLU).to(device)\n",
    "model.load_state_dict(torch.load('./models/[128, 128, 128, 128, 128]_filters_128_width__silu_2_poolsize_0.0001_lr_0.001_wd_bnorm_aug'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = ImageFolder('../data/val/', transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataloader = DataLoader(dataset, batch_size=len(dataset_test))\n",
    "X_test, Y_test = next(iter(full_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = torch.tensor([])\n",
    "# batch_size = 128\n",
    "\n",
    "# from math import ceil\n",
    "# batches = range(int(ceil(len(X_test / batch_size))))\n",
    "\n",
    "# model.eval()\n",
    "# with torch.inference_mode():\n",
    "#     for batch in batches:\n",
    "#         X_sub = X_test[batch * batch_size : min((batch+1) * batch_size, len(X_test))].to(device, non_blocking=True)\n",
    "#         preds_batch = model(X_sub)\n",
    "#         preds = torch.cat([preds, preds_batch])\n",
    "\n",
    "from model import predict\n",
    "\n",
    "preds = predict(model, X_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import CategoricalAccuracy\n",
    "\n",
    "metric = CategoricalAccuracy()\n",
    "score = metric(preds, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4825)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
